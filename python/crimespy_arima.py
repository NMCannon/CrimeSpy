# -*- coding: utf-8 -*-
"""arima.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vixt6jYICwqjiiRqZCU2tWNTCGp8JZgw
"""

import warnings
import itertools
import numpy as np
import matplotlib.pyplot as plt
warnings.filterwarnings("ignore")
plt.style.use('fivethirtyeight')
import pandas as pd
import statsmodels.api as sm
import matplotlib
matplotlib.rcParams['axes.labelsize'] = 14
matplotlib.rcParams['xtick.labelsize'] = 12
matplotlib.rcParams['ytick.labelsize'] = 12
matplotlib.rcParams['text.color'] = 'k'
!pip install xlrd==1.2.0

# Read in data as a pandas dataframe
df = pd.read_excel("crime_2010-21.xls", index_col=0)
#f["Day"] = pd.to_datetime(df["Day"]).dt.strftime("%m-%d-%Y")
#df.to_excel("crimes2014-19.xls")
#crimes = df["CRIME"]
df.head()

# Format date as datetime
df.index = pd.to_datetime(df.index)
df.index

# Convert to daily average crime by week (better plots)
y = df.resample("MS").mean()

# Plot data
y.plot(figsize=(15,6))
plt.show()

# Plot time series components
from pylab import rcParams
rcParams['figure.figsize'] = 18, 8
decomposition = sm.tsa.seasonal_decompose(y, model='additive')
fig = decomposition.plot()
plt.show()

# Example Akaike Information Criterion results
p = d = q = range(0, 2)
pdq = list(itertools.product(p, d, q))
seasonal_pdq = [(x[0], x[1], x[2], 12) for x in list(itertools.product(p, d, q))]
print('Examples of parameter combinations for Seasonal ARIMA...')
print('SARIMAX: {} x {}'.format(pdq[1], seasonal_pdq[1]))
print('SARIMAX: {} x {}'.format(pdq[1], seasonal_pdq[2]))
print('SARIMAX: {} x {}'.format(pdq[2], seasonal_pdq[3]))
print('SARIMAX: {} x {}'.format(pdq[2], seasonal_pdq[4]))

# Parameter Selection with AIC
for param in pdq:
  for param_seasonal in seasonal_pdq:
    try:
      mod = sm.tsa.statespace.SARIMAX(y,
      order=param,
      seasonal_order=param_seasonal,
      enforce_stationarity=False,
      enforce_invertibility=False)
      results = mod.fit()
      print('ARIMA{}x{}12 - AIC:{}'.format(param, param_seasonal, results.aic))
    except:
        continue

# Fitting the ARIMA model
mod = sm.tsa.statespace.SARIMAX(y,
                                order=(1, 1, 1),
                                seasonal_order=(0, 1, 1, 12),
                                enforce_stationarity=False,
                                enforce_invertibility=False)
results = mod.fit()
print(results.summary().tables[1])

# Show model diagnostics
results.plot_diagnostics(figsize=(16, 8))
plt.show()

# Validating forecast
pred = results.get_prediction(start=pd.to_datetime('2019-01-01'), dynamic=False)
pred_ci = pred.conf_int()
ax = y['2010':].plot(label='observed')
pred.predicted_mean.plot(ax=ax, label='One-step ahead Forecast', alpha=.7, figsize=(14, 7))
ax.fill_between(pred_ci.index,
                pred_ci.iloc[:, 0],
                pred_ci.iloc[:, 1], color='k', alpha=.2)
ax.set_xlabel('Date')
ax.set_ylabel('Crime')
plt.legend()
plt.show()

# Get Mean Squared Error
y_forecasted = pred.predicted_mean
y_truth = y['2019-01-01':]
mse = ((y_forecasted - y_truth) ** 2).mean()
print(format(round(mse, 2)))

# Get Root Meaned Squared Error
print(format(round(np.sqrt(mse), 2)))

# Get Mean Absolute Error
from sklearn.metrics import mean_absolute_error
mean_absolute_error(y_truth, y_forecasted)

# Get Mean Absolute Error Percentage
from sklearn.metrics import mean_absolute_percentage_error
mean_absolute_percentage_error(y_truth, y_forecasted)*100

# Generate predictions
pred_uc = results.get_forecast(steps=50)
pred_ci = pred_uc.conf_int()
ax = y.plot(label='observed', figsize=(14, 7))
pred_uc.predicted_mean.plot(ax=ax, label='Forecast')
# Fill between the higher and lower estimates
ax.fill_between(pred_ci.index,
                pred_ci.iloc[:, 0],
                pred_ci.iloc[:, 1], color='k', alpha=.25)
ax.set_xlabel('Date')
ax.set_ylabel('Crime')
plt.legend()
#pred_ci.to_csv('pred.csv')
plt.show()